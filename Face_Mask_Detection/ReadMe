This project was a part of the Statistical Methods for High Dimensional Data course, where we delved into various strategies for handling high-dimensional data and addressing challenges related to the Curse of Dimensionality and Concentration of Measures.
The topics covered in the course included Lasso Regularization and its variants (Elastic-net, Group Lasso, Fused Lasso, Generalized Lasso, Adaptive Lasso), Splines, Generalized Additive Models, and Statistical Graph Analysis.
Our project centered around a binary image classification problem: determining whether the subject in a photo is wearing a face mask or not. A unique aspect of this challenge was that we tackled the classification task using only regularized linear models, eschewing the use of convolutional neural networks.
To approach the problem, we extensively tested linear models with different Lasso regularization techniques. Additionally, we explored the use of fused lasso as a method to denoise the images, drawing comparisons also with PCA approach.
Classic Lasso and Adaptive Lasso (initialized via Ridge Regression) regularization were employed to identify the individual pixels that had the most significant influence on the classification outcome. Moreover, we harnessed Group Lasso to discern larger groups of pixels (image regions) most crucial for classification purposes.
Our regularization techniques were applied to Linear Regression, Logistic Regression, and Support Vector Machine models, enabling us to evaluate their effectiveness in handling the image classification task.
The primary code for the project is located in the R file, while additional implementations of Decision Tree, Random Forest, and a basic CNN can be found in the Jupyter Notebook.
The latter models were implemented solely for the purpose of comparison; therefore, they are basic and not the primary focus of our study.
As expected, the results obtained from regularized linear models cannot be directly compared to the performance of Convolutional Neural Networks (CNNs) in image classification tasks. Nevertheless, our exploration yielded valuable insights into the power and versatility of Lasso regularization techniques.
